{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Sequence Model Approach\n",
    "\n",
    "* The more 'classical' approach to solving this problem\n",
    "* Train a model that can take any number of 'steps'\n",
    "* Makes a prediction on next step based on previous steps\n",
    "* Learn from full tracks\n",
    "* For test tracks, predict what the next step's values will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, LeakyReLU, Dropout, ReLU, GRU, TimeDistributed, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from jlab import load_test_data, get_test_detector_plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load up and prep the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('MLchallenge2_training.csv')\n",
    "X_test = load_test_data('test_in.csv')\n",
    "eval_planes = get_test_detector_plane(X_test)\n",
    "\n",
    "# Also, load our truth values\n",
    "y_true = pd.read_csv('test_prediction.csv', names=['x', 'y', 'px', 'py', 'pz'],\n",
    "                     header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "      <th>pz</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>px1</th>\n",
       "      <th>...</th>\n",
       "      <th>z23</th>\n",
       "      <th>px23</th>\n",
       "      <th>py23</th>\n",
       "      <th>pz23</th>\n",
       "      <th>x24</th>\n",
       "      <th>y24</th>\n",
       "      <th>z24</th>\n",
       "      <th>px24</th>\n",
       "      <th>py24</th>\n",
       "      <th>pz24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.877</td>\n",
       "      <td>1.322</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-0.244</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>2.414</td>\n",
       "      <td>-10.669</td>\n",
       "      <td>0.330</td>\n",
       "      <td>176.944</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786</td>\n",
       "      <td>-2.483</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.432</td>\n",
       "      <td>2.593</td>\n",
       "      <td>7.366</td>\n",
       "      <td>15.502</td>\n",
       "      <td>176.944</td>\n",
       "      <td>0.206</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.134</td>\n",
       "      <td>-26.531</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.953</td>\n",
       "      <td>-7.586</td>\n",
       "      <td>-30.687</td>\n",
       "      <td>176.944</td>\n",
       "      <td>0.027</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.454</td>\n",
       "      <td>2.805</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.069</td>\n",
       "      <td>1.833</td>\n",
       "      <td>18.043</td>\n",
       "      <td>6.797</td>\n",
       "      <td>176.944</td>\n",
       "      <td>0.013</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.552</td>\n",
       "      <td>-19.196</td>\n",
       "      <td>65.0</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>2.366</td>\n",
       "      <td>15.068</td>\n",
       "      <td>-19.750</td>\n",
       "      <td>176.944</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>...</td>\n",
       "      <td>341.28</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>2.351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>343.405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x       y     z     px     py     pz      x1      y1       z1    px1  \\\n",
       "0   0.877   1.322  65.0 -0.244 -0.053  2.414 -10.669   0.330  176.944 -0.254   \n",
       "1   0.786  -2.483  65.0  0.103  0.432  2.593   7.366  15.502  176.944  0.206   \n",
       "2 -13.134 -26.531  65.0  0.064 -0.021  0.953  -7.586 -30.687  176.944  0.027   \n",
       "3  18.454   2.805  65.0 -0.019  0.069  1.833  18.043   6.797  176.944  0.013   \n",
       "4  15.552 -19.196  65.0 -0.010 -0.011  2.366  15.068 -19.750  176.944 -0.014   \n",
       "\n",
       "   ...     z23   px23   py23   pz23  x24  y24      z24  px24  py24  pz24  \n",
       "0  ...     NaN    NaN    NaN    NaN  NaN  NaN      NaN   NaN   NaN   NaN  \n",
       "1  ...     NaN    NaN    NaN    NaN  NaN  NaN      NaN   NaN   NaN   NaN  \n",
       "2  ...     NaN    NaN    NaN    NaN  NaN  NaN      NaN   NaN   NaN   NaN  \n",
       "3  ...     NaN    NaN    NaN    NaN  NaN  NaN      NaN   NaN   NaN   NaN  \n",
       "4  ...  341.28 -0.014 -0.002  2.351  NaN  NaN  343.405   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "      <th>pz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-23.123945</td>\n",
       "      <td>3.142886</td>\n",
       "      <td>-0.235592</td>\n",
       "      <td>0.091612</td>\n",
       "      <td>2.413377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.633486</td>\n",
       "      <td>32.319292</td>\n",
       "      <td>0.314376</td>\n",
       "      <td>0.316425</td>\n",
       "      <td>2.592952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.308506</td>\n",
       "      <td>-39.299613</td>\n",
       "      <td>-0.020097</td>\n",
       "      <td>-0.051232</td>\n",
       "      <td>0.948906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.918838</td>\n",
       "      <td>10.664617</td>\n",
       "      <td>0.038102</td>\n",
       "      <td>0.047740</td>\n",
       "      <td>1.864014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.649239</td>\n",
       "      <td>-20.616935</td>\n",
       "      <td>-0.015548</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>2.323953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x          y        px        py        pz\n",
       "0 -23.123945   3.142886 -0.235592  0.091612  2.413377\n",
       "1  19.633486  32.319292  0.314376  0.316425  2.592952\n",
       "2  -8.308506 -39.299613 -0.020097 -0.051232  0.948906\n",
       "3  19.918838  10.664617  0.038102  0.047740  1.864014\n",
       "4  13.649239 -20.616935 -0.015548  0.001471  2.323953"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the training data and targets\n",
    "\n",
    "* For each track\n",
    "  * Choose a number N between 8 and 24\n",
    "  * That track will have 6 kinematics for N blocks\n",
    "  * The target variable will be the 6 kinematic variables for the N+1th detector block\n",
    "* This will cause variable length sequences\n",
    "* Apply `pad_sequences` to prepend with zeros appropriately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = len(X_train)\n",
    "N_DETECTORS = 25\n",
    "N_KINEMATICS = 6\n",
    "SHAPE = (N_SAMPLES, N_DETECTORS-1, N_KINEMATICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = []\n",
    "y_train_array = np.ndarray(shape=(N_SAMPLES, N_KINEMATICS-1))\n",
    "for ix in range(N_SAMPLES):\n",
    "    seq_len = np.random.choice(range(8, 25))\n",
    "    track = X_train.iloc[ix].values.reshape(N_DETECTORS, N_KINEMATICS)\n",
    "    X_train_list.append(track[0:seq_len])\n",
    "    # Store the kinematics of the next in the sequence\n",
    "    # Ignore the 3rd one, which is z\n",
    "    y_train_array[ix] = track[seq_len][[0,1,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "17\n",
      "16\n",
      "22\n",
      "9\n",
      "11\n",
      "13\n",
      "22\n",
      "24\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for track in X_train_list[:10]:\n",
    "    print(len(track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = pad_sequences(X_train_list, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "for track in X_train_list[:10]:\n",
    "    print(len(track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194601, 24, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array = np.array(X_train_list)\n",
    "X_train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194601, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TEST_SAMPLES = len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_array = y_true.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_list = []\n",
    "for ix in range(N_TEST_SAMPLES):\n",
    "    seq_len = get_test_detector_plane(X_test.iloc[ix])\n",
    "    track = X_test.iloc[ix].values.reshape(N_DETECTORS, N_KINEMATICS)\n",
    "    X_test_list.append(track[0:seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_list = pad_sequences(X_test_list, dtype=float)\n",
    "X_test_array = np.array(X_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 24, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation=LeakyReLU(), input_shape=(N_DETECTORS-1, N_KINEMATICS)))\n",
    "    model.add(Dense(100, activation=LeakyReLU()))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(N_KINEMATICS-1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 200)               165600    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 186,205\n",
      "Trainable params: 186,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194601 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "194601/194601 [==============================] - 259s 1ms/sample - loss: 116.3854 - val_loss: 5.4352\n",
      "Epoch 2/5\n",
      "194601/194601 [==============================] - 233s 1ms/sample - loss: 1.8483 - val_loss: 3.8398\n",
      "Epoch 3/5\n",
      "194601/194601 [==============================] - 206s 1ms/sample - loss: 0.6441 - val_loss: 0.2240\n",
      "Epoch 4/5\n",
      "194601/194601 [==============================] - 248s 1ms/sample - loss: 0.2546 - val_loss: 0.1212\n",
      "Epoch 5/5\n",
      "194601/194601 [==============================] - 252s 1ms/sample - loss: 0.1832 - val_loss: 0.1357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3b85b1d0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(x=X_train_array, y=y_train_array, validation_data=(X_test_array, y_test_array), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194601 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "194601/194601 [==============================] - 218s 1ms/sample - loss: 326.7025 - val_loss: 4.9697\n",
      "Epoch 2/50\n",
      "194601/194601 [==============================] - 198s 1ms/sample - loss: 4.7569 - val_loss: 1.5031\n",
      "Epoch 3/50\n",
      "194601/194601 [==============================] - 192s 989us/sample - loss: 2.2188 - val_loss: 0.7064\n",
      "Epoch 4/50\n",
      "194601/194601 [==============================] - 189s 973us/sample - loss: 1.6142 - val_loss: 0.3873\n",
      "Epoch 5/50\n",
      "194601/194601 [==============================] - 190s 975us/sample - loss: 1.3676 - val_loss: 0.2826\n",
      "Epoch 6/50\n",
      "194601/194601 [==============================] - 190s 977us/sample - loss: 1.2523 - val_loss: 0.2624\n",
      "Epoch 7/50\n",
      "194601/194601 [==============================] - 192s 984us/sample - loss: 1.2170 - val_loss: 0.1198\n",
      "Epoch 8/50\n",
      "194601/194601 [==============================] - 191s 984us/sample - loss: 1.1980 - val_loss: 0.3450\n",
      "Epoch 9/50\n",
      "194601/194601 [==============================] - 190s 974us/sample - loss: 1.2492 - val_loss: 0.1498\n",
      "Epoch 10/50\n",
      "194601/194601 [==============================] - 188s 967us/sample - loss: 109.6867 - val_loss: 135.0494\n",
      "Epoch 11/50\n",
      "194601/194601 [==============================] - 191s 979us/sample - loss: 3628.7882 - val_loss: 145.1902\n",
      "Epoch 12/50\n",
      "194601/194601 [==============================] - 192s 987us/sample - loss: 147.6975 - val_loss: 143.6387\n",
      "Epoch 13/50\n",
      "194601/194601 [==============================] - 191s 982us/sample - loss: 135.3904 - val_loss: 136.1410\n",
      "Epoch 14/50\n",
      "194601/194601 [==============================] - 190s 976us/sample - loss: 138.0715 - val_loss: 142.0082\n",
      "Epoch 15/50\n",
      "194601/194601 [==============================] - 190s 975us/sample - loss: 150.2713 - val_loss: 122.1642\n",
      "Epoch 16/50\n",
      "194601/194601 [==============================] - 191s 981us/sample - loss: 194.4811 - val_loss: 157.4011\n",
      "Epoch 17/50\n",
      "194601/194601 [==============================] - 191s 982us/sample - loss: 295.3036 - val_loss: 981.5715\n",
      "Epoch 18/50\n",
      "194601/194601 [==============================] - 193s 990us/sample - loss: 1135.6556 - val_loss: 149.0931\n",
      "Epoch 19/50\n",
      "194601/194601 [==============================] - 191s 980us/sample - loss: 2282.8591 - val_loss: 143.4084\n",
      "Epoch 20/50\n",
      "194601/194601 [==============================] - 191s 981us/sample - loss: 1515.8976 - val_loss: 1430.2080\n",
      "Epoch 21/50\n",
      "194601/194601 [==============================] - 192s 984us/sample - loss: 4582.7446 - val_loss: 184.3361\n",
      "Epoch 22/50\n",
      "194601/194601 [==============================] - 191s 981us/sample - loss: 2602.9031 - val_loss: 149.0369\n",
      "Epoch 23/50\n",
      "194601/194601 [==============================] - 191s 983us/sample - loss: 9676.4073 - val_loss: 149.6423\n",
      "Epoch 24/50\n",
      "194601/194601 [==============================] - 191s 980us/sample - loss: 7239.8273 - val_loss: 239.0134\n",
      "Epoch 25/50\n",
      "194601/194601 [==============================] - 192s 985us/sample - loss: 8267.8885 - val_loss: 193.2975\n",
      "Epoch 26/50\n",
      "194601/194601 [==============================] - 191s 982us/sample - loss: 21609147.9409 - val_loss: 1354990.5196\n",
      "Epoch 27/50\n",
      "194601/194601 [==============================] - 191s 981us/sample - loss: 188188.0964 - val_loss: 8307.5244\n",
      "Epoch 28/50\n",
      "194601/194601 [==============================] - 191s 980us/sample - loss: 11133.2162 - val_loss: 735.8909\n",
      "Epoch 29/50\n",
      "194601/194601 [==============================] - 192s 988us/sample - loss: 27304.7013 - val_loss: 550.2246\n",
      "Epoch 30/50\n",
      "194601/194601 [==============================] - 191s 979us/sample - loss: 3500210.6721 - val_loss: 6881.0110\n",
      "Epoch 31/50\n",
      "194601/194601 [==============================] - 191s 982us/sample - loss: 12381243691.6794 - val_loss: 232697165.3480\n",
      "Epoch 32/50\n",
      "194601/194601 [==============================] - 191s 981us/sample - loss: 704356007.8062 - val_loss: 1588541.0581\n",
      "Epoch 33/50\n",
      "194601/194601 [==============================] - 191s 980us/sample - loss: 5890180.5563 - val_loss: 13965.1964\n",
      "Epoch 34/50\n",
      "194601/194601 [==============================] - 191s 983us/sample - loss: 91581942.6742 - val_loss: 2227.1191\n",
      "Epoch 35/50\n",
      "194601/194601 [==============================] - 191s 982us/sample - loss: 566871311591.0952 - val_loss: 82189.5131\n",
      "Epoch 36/50\n",
      "194601/194601 [==============================] - 191s 980us/sample - loss: 13115223.4457 - val_loss: 860606.4987\n",
      "Epoch 37/50\n",
      "194601/194601 [==============================] - 194s 995us/sample - loss: 721692019.6183 - val_loss: 1078563464.5220\n",
      "Epoch 38/50\n",
      "194601/194601 [==============================] - 191s 982us/sample - loss: nan - val_loss: nan\n",
      "Epoch 39/50\n",
      "194601/194601 [==============================] - 191s 980us/sample - loss: nan - val_loss: nan\n",
      "Epoch 40/50\n",
      "194601/194601 [==============================] - 193s 990us/sample - loss: nan - val_loss: nan\n",
      "Epoch 41/50\n",
      "194601/194601 [==============================] - 192s 987us/sample - loss: nan - val_loss: nan\n",
      "Epoch 42/50\n",
      "194601/194601 [==============================] - 191s 980us/sample - loss: nan - val_loss: nan\n",
      "Epoch 43/50\n",
      "194601/194601 [==============================] - 192s 984us/sample - loss: nan - val_loss: nan\n",
      "Epoch 44/50\n",
      "194601/194601 [==============================] - 192s 985us/sample - loss: nan - val_loss: nan\n",
      "Epoch 45/50\n",
      "194601/194601 [==============================] - 192s 989us/sample - loss: nan - val_loss: nan\n",
      "Epoch 46/50\n",
      "194601/194601 [==============================] - 192s 984us/sample - loss: nan - val_loss: nan\n",
      "Epoch 47/50\n",
      "194601/194601 [==============================] - 191s 983us/sample - loss: nan - val_loss: nan\n",
      "Epoch 48/50\n",
      "194601/194601 [==============================] - 191s 983us/sample - loss: nan - val_loss: nan\n",
      "Epoch 49/50\n",
      "194601/194601 [==============================] - 191s 981us/sample - loss: nan - val_loss: nan\n",
      "Epoch 50/50\n",
      "194601/194601 [==============================] - 193s 990us/sample - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train_array, y=y_train_array,\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    epochs=50, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194601 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "194601/194601 [==============================] - 198s 1ms/sample - loss: 249.5579 - val_loss: 0.7746\n",
      "Epoch 2/20\n",
      "194601/194601 [==============================] - 2346s 12ms/sample - loss: 2.5781 - val_loss: 0.6244\n",
      "Epoch 3/20\n",
      "194601/194601 [==============================] - 202s 1ms/sample - loss: 1.7952 - val_loss: 0.3346\n",
      "Epoch 4/20\n",
      "194601/194601 [==============================] - 195s 1ms/sample - loss: 1.3872 - val_loss: 0.1804\n",
      "Epoch 5/20\n",
      "194601/194601 [==============================] - 196s 1ms/sample - loss: 1.2802 - val_loss: 0.1384\n",
      "Epoch 6/20\n",
      "194601/194601 [==============================] - 195s 1ms/sample - loss: 1.2745 - val_loss: 0.2104\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "history = model.fit(x=X_train_array, y=y_train_array,\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    callbacks=[es], epochs=20, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lstm100-dense100-dropout025-epochs20-early-stopping.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 722.3176 - val_loss: 23.1267\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 25.8648 - val_loss: 9.7359\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 13.8674 - val_loss: 4.2730\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 9.6217 - val_loss: 2.6301\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 7.4191 - val_loss: 1.9886\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 6.2753 - val_loss: 2.1294\n"
     ]
    }
   ],
   "source": [
    "def lstm_model_lin():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation=LeakyReLU(), input_shape=(N_DETECTORS-1, N_KINEMATICS)))\n",
    "    model.add(Dense(100, activation=LeakyReLU()))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(N_KINEMATICS-1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "lin_act_model = lstm_model_lin()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "history = lin_act_model.fit(x=X_train_array[:10000], y=y_train_array[:10000],\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    callbacks=[es], epochs=20, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 305.4409 - val_loss: 16.1725\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 19.2072 - val_loss: 6.6038\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 10.8057 - val_loss: 4.2676\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 7.9416 - val_loss: 2.1789\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 6.2256 - val_loss: 2.3635\n"
     ]
    }
   ],
   "source": [
    "def lstm_model_adam():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation=LeakyReLU(), input_shape=(N_DETECTORS-1, N_KINEMATICS)))\n",
    "    model.add(Dense(100, activation=LeakyReLU()))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(N_KINEMATICS-1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "adam_model = lstm_model_adam()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "history = adam_model.fit(x=X_train_array[:10000], y=y_train_array[:10000],\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    callbacks=[es], epochs=20, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 2095.8651 - val_loss: 253.8501\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 305.1297 - val_loss: 85.6102\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 143.2311 - val_loss: 64.7771\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 66.5812 - val_loss: 36.7483\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 45.9202 - val_loss: 25.6323\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 35.9694 - val_loss: 19.3018\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 30.0887 - val_loss: 16.9329\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 25.2751 - val_loss: 12.3551\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 21.4555 - val_loss: 10.0203\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 19.4236 - val_loss: 10.1653\n"
     ]
    }
   ],
   "source": [
    "def lstm_model_dropout50():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation=LeakyReLU(), input_shape=(N_DETECTORS-1, N_KINEMATICS)))\n",
    "    model.add(Dense(100, activation=LeakyReLU()))\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(N_KINEMATICS-1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "dropout50_model = lstm_model_dropout50()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "history = dropout50_model.fit(x=X_train_array[:10000], y=y_train_array[:10000],\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    callbacks=[es], epochs=20, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 303.2399 - val_loss: 28.9260\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 22.5050 - val_loss: 23.4065\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 17.9289 - val_loss: 13.7558\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 12.5689 - val_loss: 9.9349\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 9.5144 - val_loss: 8.0810\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 8.5819 - val_loss: 8.3551\n"
     ]
    }
   ],
   "source": [
    "def lstm_model_nodropout():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation=LeakyReLU(), input_shape=(N_DETECTORS-1, N_KINEMATICS)))\n",
    "    model.add(Dense(100, activation=LeakyReLU()))\n",
    "    model.add(Dense(N_KINEMATICS-1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "nodropout_model = lstm_model_nodropout()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "history = nodropout_model.fit(x=X_train_array[:10000], y=y_train_array[:10000],\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    callbacks=[es], epochs=20, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 187.4669 - val_loss: 17.1837\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 20.4060 - val_loss: 5.7464\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 12.9890 - val_loss: 2.9215\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 10.3698 - val_loss: 3.3642\n"
     ]
    }
   ],
   "source": [
    "def lstm_model_relu():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(N_DETECTORS-1, N_KINEMATICS)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(N_KINEMATICS-1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "relu_model = lstm_model_relu()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "history = relu_model.fit(x=X_train_array[:10000], y=y_train_array[:10000],\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    callbacks=[es], epochs=20, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 15.1533 - val_loss: 0.9619\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 3.2930 - val_loss: 0.6037\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 2.6465 - val_loss: 0.8654\n"
     ]
    }
   ],
   "source": [
    "def model_gru():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(200, activation=LeakyReLU(), input_shape=(N_DETECTORS-1, N_KINEMATICS)))\n",
    "    model.add(Dense(100, activation=LeakyReLU()))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(N_KINEMATICS-1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "gru_model = model_gru()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "history = gru_model.fit(x=X_train_array[:10000], y=y_train_array[:10000],\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    callbacks=[es], epochs=20, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Conclusions\n",
    "\n",
    "* GRU > LSTM\n",
    "* LeakyReLU > ReLU\n",
    "* adam > rmsprop\n",
    "* dropout 0.25 > dropout 0.5 > no dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194601 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "194601/194601 [==============================] - 208s 1ms/sample - loss: 2.3328 - val_loss: 0.3510\n",
      "Epoch 2/8\n",
      "194601/194601 [==============================] - 202s 1ms/sample - loss: 1.3041 - val_loss: 0.1264\n",
      "Epoch 3/8\n",
      "194601/194601 [==============================] - 204s 1ms/sample - loss: 1.2133 - val_loss: 0.2112\n"
     ]
    }
   ],
   "source": [
    "def model_v2():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(200, activation=LeakyReLU(), input_shape=(N_DETECTORS-1, N_KINEMATICS)))\n",
    "    model.add(Dense(100, activation=LeakyReLU()))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(N_KINEMATICS-1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "v2_model = model_v2()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "history = v2_model.fit(x=X_train_array, y=y_train_array,\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    callbacks=[es], epochs=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 24, 30)            3420      \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 24, 30)            5580      \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 30)                5580      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               3100      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 18,185\n",
      "Trainable params: 18,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_v2_deep():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(30, activation=LeakyReLU(), input_shape=(N_DETECTORS-1, N_KINEMATICS),\n",
    "                  return_sequences=True))\n",
    "    model.add(GRU(30, activation=LeakyReLU(), return_sequences=True))\n",
    "    model.add(GRU(30, activation=LeakyReLU()))\n",
    "    model.add(Dense(100, activation=LeakyReLU()))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(N_KINEMATICS-1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "v2_model_deep = model_v2_deep()\n",
    "v2_model_deep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194601 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "194601/194601 [==============================] - 304s 2ms/sample - loss: 2.8970 - val_loss: 0.4792\n",
      "Epoch 2/8\n",
      "194601/194601 [==============================] - 290s 1ms/sample - loss: 1.5549 - val_loss: 0.5346\n",
      "Epoch 3/8\n",
      "194601/194601 [==============================] - 281s 1ms/sample - loss: 1.3498 - val_loss: 0.3451\n",
      "Epoch 4/8\n",
      "194601/194601 [==============================] - 275s 1ms/sample - loss: 1.4204 - val_loss: 0.4317\n",
      "Epoch 5/8\n",
      "194601/194601 [==============================] - 289s 1ms/sample - loss: 1.3467 - val_loss: 0.2232\n",
      "Epoch 6/8\n",
      "194601/194601 [==============================] - 268s 1ms/sample - loss: 1.2464 - val_loss: 0.1453\n",
      "Epoch 7/8\n",
      "194601/194601 [==============================] - 279s 1ms/sample - loss: 1.2127 - val_loss: 0.1390\n",
      "Epoch 8/8\n",
      "158144/194601 [=======================>......] - ETA: 55s - loss: 1.1842"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=2, restore_best_weights=True)\n",
    "history = v2_model_deep.fit(x=X_train_array, y=y_train_array,\n",
    "                            validation_data=(X_test_array, y_test_array),\n",
    "                            callbacks=[es],\n",
    "                            epochs=8, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 55s 3ms/sample - loss: 6.2944 - val_loss: 0.8832\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 50s 3ms/sample - loss: 2.3380 - val_loss: 0.8004\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 49s 2ms/sample - loss: 1.9149 - val_loss: 0.6378\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 50s 3ms/sample - loss: 1.8121 - val_loss: 0.4890\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 52s 3ms/sample - loss: 1.7023 - val_loss: 0.4793\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 50s 2ms/sample - loss: 1.7116 - val_loss: 0.5745\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 51s 3ms/sample - loss: 1.7073 - val_loss: 0.4136\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 51s 3ms/sample - loss: 1.6392 - val_loss: 0.6285\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 50s 2ms/sample - loss: 1.6129 - val_loss: 0.6862\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 50s 3ms/sample - loss: 1.5222 - val_loss: 0.4429\n"
     ]
    }
   ],
   "source": [
    "def model_v2_dbl_gru():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(200, activation=LeakyReLU(), input_shape=(N_DETECTORS-1, N_KINEMATICS),\n",
    "                  return_sequences=True))\n",
    "    model.add(GRU(200, activation=LeakyReLU(), input_shape=(N_DETECTORS-1, N_KINEMATICS)))\n",
    "    model.add(Dense(100, activation=LeakyReLU()))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(N_KINEMATICS-1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "v2_model_dbl_gru = model_v2_dbl_gru()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "history = v2_model_dbl_gru.fit(x=X_train_array[:20000], y=y_train_array[:20000],\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    #callbacks=[es],\n",
    "                    epochs=10, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 24s 1ms/sample - loss: 18.9925 - val_loss: 2.0618\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 4.9002 - val_loss: 1.2547\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 3.7768 - val_loss: 0.6070\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 3.2649 - val_loss: 1.2479\n"
     ]
    }
   ],
   "source": [
    "def model_v2_2x_dropout():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(200, activation=LeakyReLU(), input_shape=(N_DETECTORS-1, N_KINEMATICS)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(100, activation=LeakyReLU()))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(N_KINEMATICS-1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "v2_model_dbl_dropout = model_v2_2x_dropout()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "history = v2_model_dbl_dropout.fit(x=X_train_array[:20000], y=y_train_array[:20000],\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    callbacks=[es], epochs=20, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer gru_14 is incompatible with the layer: expected ndim=3, found ndim=5. Full shape received: [None, 1, None, 24, 6]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-da22d57a70b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mv2_model_big_gru\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_v2_big_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m history = v2_model_big_gru.fit(x=X_train_array[:20000], y=y_train_array[:20000],\n",
      "\u001b[0;32m<ipython-input-200-da22d57a70b0>\u001b[0m in \u001b[0;36mmodel_v2_big_gru\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_DETECTORS\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_KINEMATICS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    175\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 772\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer gru_14 is incompatible with the layer: expected ndim=3, found ndim=5. Full shape received: [None, 1, None, 24, 6]"
     ]
    }
   ],
   "source": [
    "def model_v2_big_gru():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(400, activation=LeakyReLU(), input_shape=(N_DETECTORS-1, N_KINEMATICS)))\n",
    "    model.add(Dense(100, activation=LeakyReLU()))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(N_KINEMATICS-1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "v2_model_big_gru = model_v2_big_gru()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "history = v2_model_big_gru.fit(x=X_train_array[:20000], y=y_train_array[:20000],\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    #callbacks=[es],\n",
    "                    epochs=10, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 11/15\n",
      "20000/20000 [==============================] - 54s 3ms/sample - loss: 1.3613 - val_loss: 0.5861\n",
      "Epoch 12/15\n",
      "20000/20000 [==============================] - 55s 3ms/sample - loss: 1.3655 - val_loss: 0.2373\n",
      "Epoch 13/15\n",
      "20000/20000 [==============================] - 54s 3ms/sample - loss: 1.2724 - val_loss: 0.1703\n",
      "Epoch 14/15\n",
      "20000/20000 [==============================] - 54s 3ms/sample - loss: 1.2940 - val_loss: 0.3137\n",
      "Epoch 15/15\n",
      "20000/20000 [==============================] - 54s 3ms/sample - loss: 1.2810 - val_loss: 0.1698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a8e946748>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2_model_big_gru.fit(x=X_train_array[:20000], y=y_train_array[:20000],\n",
    "                    validation_data=(X_test_array, y_test_array),\n",
    "                    #callbacks=[es],\n",
    "                    epochs=15, use_multiprocessing=True, initial_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try CNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194601, 24, 6)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 23, 5)             65        \n",
      "_________________________________________________________________\n",
      "gru_25 (GRU)                 (None, 200)               124200    \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 144,870\n",
      "Trainable params: 144,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def cnn_gru():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=5, kernel_size=2, strides=1, input_shape=(N_DETECTORS-1, N_KINEMATICS)))\n",
    "    #model.add(MaxPooling1D())\n",
    "    model.add(GRU(200, activation=LeakyReLU()))\n",
    "    model.add(Dense(100, activation=LeakyReLU()))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(N_KINEMATICS-1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "cnn_model = cnn_gru()\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 23s 1ms/sample - loss: 13.3734 - val_loss: 1.6757\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 22s 1ms/sample - loss: 3.0693 - val_loss: 0.8470\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 2.6314 - val_loss: 0.7303\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 2.1451 - val_loss: 0.8053\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 2.0921 - val_loss: 0.7273\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 1.9285 - val_loss: 0.4551\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 1.8432 - val_loss: 0.6966\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 1.6800 - val_loss: 0.5120\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 1.5675 - val_loss: 0.3390\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 21s 1ms/sample - loss: 1.5159 - val_loss: 0.3983\n"
     ]
    }
   ],
   "source": [
    "#es = EarlyStopping(monitor='val_loss', mode='min')\n",
    "history = cnn_model.fit(x=X_train_array[:20000], y=y_train_array[:20000],\n",
    "                      validation_data=(X_test_array, y_test_array),\n",
    "                      epochs=10, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [3.3281039200901317,\n",
       "  1.6039592637484563,\n",
       "  1.3489888134789536,\n",
       "  1.2624885631565317,\n",
       "  1.2353142021468715,\n",
       "  1.211998767219029,\n",
       "  1.1837373140878185,\n",
       "  1.1759768705626037],\n",
       " 'val_loss': [0.778679012966156,\n",
       "  0.5407980192184448,\n",
       "  0.5594191231250762,\n",
       "  0.4179811120986939,\n",
       "  0.27897539434432983,\n",
       "  0.18599163811206817,\n",
       "  0.1257927789211273,\n",
       "  0.10037544323205948]}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enough tinkering around\n",
    "\n",
    "* Formalize this into some scripts\n",
    "* Make predictions on competition test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train\n",
    "from predict import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 24, 30)            3420      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 24, 30)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 24, 30)            5580      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 24, 30)            0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 30)                5580      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               3100      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 18,185\n",
      "Trainable params: 18,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 194601 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "194601/194601 [==============================] - 308s 2ms/sample - loss: 5.6312 - val_loss: 1.2376\n",
      "Epoch 2/100\n",
      "103392/194601 [==============>...............] - ETA: 2:17 - loss: 2.2091WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7f967f082214>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dannowitz_jlab2_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Work/polymath-progression-blog/jlab-ml-lunch-2/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(frac, filename, epochs, ret_model)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     )\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    413\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1820\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1824\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train(frac=1.00, filename=\"dannowitz_jlab2_model\", epochs=100, ret_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(model_filename=\"dannowitz_jlab2_model.h5\",\n",
    "                data_filename=\"test_in (1).csv\",\n",
    "                output_filename=\"danowitz_jlab2_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
